{
    "dataset_reader": {
        "type": "seq2seq"
    },
    "train_data_path": "/apsarapangu/disk2/qibin.cqb/sigtext/data/know_card/char/train.txt",
    "validation_data_path": "/apsarapangu/disk2/qibin.cqb/sigtext/data/know_card/char/valid.txt",
    "model": {
        "type": "seq2seq",
        "source_embedder": {
            "tokens": {
                "type": "embedding",
                "embedding_dim": 256,
                "trainable": true,
                "pretrained_file": "/apsarapangu/disk2/qibin.cqb/sigtext/data/know_card/char/pretrained_emb256.txt"
            }
        },
        "encoder": {
            "type": "lstm",
            "bidirectional": true,
            "input_size": 256,
            "hidden_size": 256,
            "num_layers": 2,
            "dropout": 0.1
        },
        "max_decoding_steps": 149,
        "scheduled_sampling_ratio": 0,
        "beam_size": 5,
        "attention": {
            "type": "bilinear",
            "vector_dim": 512,
            "matrix_dim": 512
        }
    },
    "iterator": {
        "type": "bucket",
        "sorting_keys": [["source_tokens", "num_tokens"], ["target_tokens", "num_tokens"]],
        "batch_size": 64
    },
    "trainer": {
        "type": "seq2seq_trainer",
        "num_epochs": 100,
        "patience": 100,
        "cuda_device": 0,
        "grad_clipping": 1,
        "validation_metric": "-loss",
        "optimizer": {
            "type": "dense_sparse_adam",
            "lr": 3e-4,
            "betas": [0.9, 0.998],
            "eps": 1e-9
        }
    }
}

